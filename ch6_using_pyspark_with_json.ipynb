{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-the-Data\" data-toc-modified-id=\"Reading-the-Data-1\">Reading the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#JSON-params\" data-toc-modified-id=\"JSON-params-1.1\">JSON params</a></span></li></ul></li><li><span><a href=\"#Spark's-complex-column-types:-array,-map-and-struct\" data-toc-modified-id=\"Spark's-complex-column-types:-array,-map-and-struct-2\">Spark's complex column types: <code>array</code>, <code>map</code> and <code>struct</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#array\" data-toc-modified-id=\"array-2.1\"><code>array</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-an-array-column\" data-toc-modified-id=\"Creating-an-array-column-2.1.1\">Creating an array column</a></span></li><li><span><a href=\"#Use-F.size-to-show-the-number-of-elements-in-an-array\" data-toc-modified-id=\"Use-F.size-to-show-the-number-of-elements-in-an-array-2.1.2\">Use <code>F.size</code> to show the number of elements in an array</a></span></li><li><span><a href=\"#Use-F.array_distinct()-to-remove-duplicates-(like-SQL)\" data-toc-modified-id=\"Use-F.array_distinct()-to-remove-duplicates-(like-SQL)-2.1.3\">Use <code>F.array_distinct()</code> to remove duplicates (like SQL)</a></span></li><li><span><a href=\"#Use-F.array_intersect-to-show-common-values-across-arrays\" data-toc-modified-id=\"Use-F.array_intersect-to-show-common-values-across-arrays-2.1.4\">Use <code>F.array_intersect</code> to show common values across arrays</a></span></li><li><span><a href=\"#Use-array_position()-to-get-the-position-of-the-item-in-an-array-if-it-exists\" data-toc-modified-id=\"Use-array_position()-to-get-the-position-of-the-item-in-an-array-if-it-exists-2.1.5\">Use <code>array_position()</code> to get the position of the item in an array if it exists</a></span></li></ul></li><li><span><a href=\"#map\" data-toc-modified-id=\"map-2.2\"><code>map</code></a></span></li><li><span><a href=\"#struct\" data-toc-modified-id=\"struct-2.3\"><code>struct</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-explode-to-split-arrays-into-rows\" data-toc-modified-id=\"Using-explode-to-split-arrays-into-rows-2.3.1\">Using <code>explode</code> to split arrays into rows</a></span></li></ul></li></ul></li><li><span><a href=\"#How-to-define-and-use-a-schema-with-a-PySpark-data-frame\" data-toc-modified-id=\"How-to-define-and-use-a-schema-with-a-PySpark-data-frame-3\">How to define and use a schema with a PySpark data frame</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Building-the-entire-schema-from-scratch\" data-toc-modified-id=\"Building-the-entire-schema-from-scratch-3.0.1\">Building the entire schema from scratch</a></span></li></ul></li></ul></li><li><span><a href=\"#Reading-JSON-with-a-strict-schema\" data-toc-modified-id=\"Reading-JSON-with-a-strict-schema-4\">Reading JSON with a strict schema</a></span></li><li><span><a href=\"#Defining-your-schema-in-JSON\" data-toc-modified-id=\"Defining-your-schema-in-JSON-5\">Defining your schema in JSON</a></span><ul class=\"toc-item\"><li><span><a href=\"#Array-types\" data-toc-modified-id=\"Array-types-5.1\">Array types</a></span></li><li><span><a href=\"#Map-types\" data-toc-modified-id=\"Map-types-5.2\">Map types</a></span></li></ul></li><li><span><a href=\"#Reducing-duplicate-data-with-complex-data-types\" data-toc-modified-id=\"Reducing-duplicate-data-with-complex-data-types-6\">Reducing duplicate data with complex data types</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hierarchichal-vs-2-D-row-column-models\" data-toc-modified-id=\"Hierarchichal-vs-2-D-row-column-models-6.1\">Hierarchichal vs 2-D row-column models</a></span><ul class=\"toc-item\"><li><span><a href=\"#shows-data-frame-using-a-hierarchical-model\" data-toc-modified-id=\"shows-data-frame-using-a-hierarchical-model-6.1.1\"><code>shows</code> data frame using a hierarchical model</a></span></li></ul></li></ul></li><li><span><a href=\"#How-to-use-explode-and-collect-operations-to-go-from-hierarchical-to-tabular-and-back\" data-toc-modified-id=\"How-to-use-explode-and-collect-operations-to-go-from-hierarchical-to-tabular-and-back-7\">How to use <code>explode</code> and <code>collect</code> operations to go from hierarchical to tabular and back</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploding-a-map\" data-toc-modified-id=\"Exploding-a-map-7.1\">Exploding a <code>map</code></a></span></li><li><span><a href=\"#collect-ing-records-into-a-complex-column\" data-toc-modified-id=\"collect-ing-records-into-a-complex-column-7.2\"><code>collect</code>-ing records into a complex column</a></span><ul class=\"toc-item\"><li><span><a href=\"#collect_list()-and-collect_set()\" data-toc-modified-id=\"collect_list()-and-collect_set()-7.2.1\"><code>collect_list()</code> and <code>collect_set()</code></a></span></li></ul></li><li><span><a href=\"#Building-your-own-hierarchies-with-struct()\" data-toc-modified-id=\"Building-your-own-hierarchies-with-struct()-7.3\">Building your own hierarchies with <code>struct()</code></a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-dimensional data frames: using PySpark with JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data\n",
    "\n",
    "For this chapter, we use a JSON dump of the information about the TV Show Silicon Valley, from TV Maze.\n",
    "\n",
    "### JSON params\n",
    "\n",
    "- No need for delimiters like CSV\n",
    "- No need to infer data type\n",
    "- Contains __hierarchical data__, unlike CSVs\n",
    "- Single JSON: __one JSON document, one line, one record__.\n",
    "- Multiple JSON (`multiLine`):  __one JSON document, one FILE, one record__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import a single JSON document\n",
    "sv = \"data/ch06/shows-silicon-valley.json\"\n",
    "shows = spark.read.json(sv)\n",
    "display(shows.count())\n",
    "\n",
    "\n",
    "# Read multiple JSON documents using multiLine param\n",
    "three_shows = spark.read.json(\"data/ch06/shows-*.json\", multiLine=True)\n",
    "display(three_shows.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the schema\n",
    "shows.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark's complex column types: `array`, `map` and `struct`\n",
    "\n",
    "### `array`\n",
    "\n",
    "- PySpark arrays are containers for values of the same type, unlike JSON.\n",
    "- __PySpark will not raise an error if you try to read an array-type column with multiple types__. Instead, it will simply default to the lowest common denominator, usually the string.\n",
    "- Many array functions are available from `pyspark.sql.functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|name          |genres  |\n",
      "+--------------+--------+\n",
      "|Silicon Valley|[Comedy]|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting the name and genres columns of the shows dataframe\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "array_subset = shows.select(\"name\", \"genres\")\n",
    "array_subset.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "|          name|dot_and_index|col_and_index|dot_and_method|col_and_method|\n",
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "|Silicon Valley|       Comedy|       Comedy|        Comedy|        Comedy|\n",
      "+--------------+-------------+-------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple methods to extract the same array\n",
    "\n",
    "array_subset = array_subset.select(\n",
    "    \"name\",\n",
    "    array_subset.genres[0].alias(\"dot_and_index\"),\n",
    "    F.col(\"genres\")[0].alias(\"col_and_index\"),\n",
    "    array_subset.genres.getItem(0).alias(\"dot_and_method\"),\n",
    "    F.col(\"genres\").getItem(0).alias(\"col_and_method\"),\n",
    ")\n",
    "\n",
    "array_subset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARNING: Although the square bracket approach looks very Pythonic, __you can’t use it as a slicing tool__. PySpark will accept only one integer as an index.\n",
    "\n",
    "#### Creating an array column\n",
    "\n",
    "1. Create three literal columns (using `lit()` to create scalar columns, then `make_array()`) to create an array of possible genres.\n",
    "2. Use the function `array_repeat()` to create a column repeating the \"Comedy\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+----------------------------------------+\n",
      "|name          |Some_Genres            |Repeated_Genres                         |\n",
      "+--------------+-----------------------+----------------------------------------+\n",
      "|Silicon Valley|[Comedy, Horror, Drama]|[Comedy, Comedy, Comedy, Comedy, Comedy]|\n",
      "+--------------+-----------------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Create three literal columns (using lit() to create scalar columns, \n",
    "   then make_array() to ) to create an array of possible genres.\n",
    "2. Use the function array_repeat() to create a column repeating the \"Comedy\" string\n",
    "\"\"\"\n",
    "\n",
    "array_subset_repeated = array_subset.select(\n",
    "    \"name\",\n",
    "    F.lit(\"Comedy\").alias(\"one\"),\n",
    "    F.lit(\"Horror\").alias(\"two\"),\n",
    "    F.lit(\"Drama\").alias(\"three\"),\n",
    "    F.col(\"dot_and_index\"),\n",
    ").select(\n",
    "    \"name\",\n",
    "    F.array(\"one\", \"two\", \"three\").alias(\"Some_Genres\"),\n",
    "    F.array_repeat(\"dot_and_index\", 5).alias(\"Repeated_Genres\"),\n",
    ")\n",
    "\n",
    "array_subset_repeated.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `F.size` to show the number of elements in an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+---------------------+\n",
      "|          name|size(Some_Genres)|size(Repeated_Genres)|\n",
      "+--------------+-----------------+---------------------+\n",
      "|Silicon Valley|                3|                    5|\n",
      "+--------------+-----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array_subset_repeated.select(\n",
    "    \"name\", F.size(\"Some_Genres\"), F.size(\"Repeated_Genres\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `F.array_distinct()` to remove duplicates (like SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------+-------------------------------+\n",
      "|name          |array_distinct(Some_Genres)|array_distinct(Repeated_Genres)|\n",
      "+--------------+---------------------------+-------------------------------+\n",
      "|Silicon Valley|[Comedy, Horror, Drama]    |[Comedy]                       |\n",
      "+--------------+---------------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array_subset_repeated.select(\n",
    "    \"name\",\n",
    "    F.array_distinct(\"Some_Genres\"),\n",
    "    F.array_distinct(\"Repeated_Genres\")\n",
    ").show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `F.array_intersect` to show common values across arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|          name|  Genres|\n",
      "+--------------+--------+\n",
      "|Silicon Valley|[Comedy]|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array_subset_repeated = array_subset_repeated.select(\n",
    "    \"name\", \n",
    "    F.array_intersect(\"Some_Genres\", \"Repeated_Genres\").alias(\"Genres\")\n",
    ")\n",
    "\n",
    "array_subset_repeated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `array_position()` to get the position of the item in an array if it exists\n",
    "\n",
    "> WARNING: `array_position` is 1-based, unlike Python lists or extracting elements from arrays (e.g. ` array_subset.genres[0]` or `getItems(0)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|          name|Genres|\n",
      "+--------------+------+\n",
      "|Silicon Valley|     1|\n",
      "+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When using array_position(), the first item of the array has position 1, \n",
    "# not 0 like in python.\n",
    "array_subset_repeated.select(\n",
    "    \"name\",\n",
    "    F.array_position(\"Genres\", \"Comedy\").alias(\"Genres\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `map`\n",
    "\n",
    "- Like Python typed dictionary: you have keys and values just like in a dictionary, \n",
    "- Like `array`, keys need to be of the same type and the values need to be of the same type\n",
    "- Values can usually be null, but keys can’t (like Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two columns of arays\n",
      "+----------------------+-----------------------------------+\n",
      "|keys                  |values                             |\n",
      "+----------------------+-----------------------------------+\n",
      "|[name, language, type]|[Silicon Valley, English, Scripted]|\n",
      "+----------------------+-----------------------------------+\n",
      "\n",
      "root\n",
      " |-- mapped: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "1 column of map\n",
      "+---------------------------------------------------------------+\n",
      "|mapped                                                         |\n",
      "+---------------------------------------------------------------+\n",
      "|[name -> Silicon Valley, language -> English, type -> Scripted]|\n",
      "+---------------------------------------------------------------+\n",
      "\n",
      "3 ways to select a key in a map\n",
      "+--------------+--------------+--------------+\n",
      "|          name|  mapped[name]|  mapped[name]|\n",
      "+--------------+--------------+--------------+\n",
      "|Silicon Valley|Silicon Valley|Silicon Valley|\n",
      "+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a map from two arrays: one for the keys, one for the values. \n",
    "# This creates a hash-map within the column record.\n",
    "\n",
    "# 1. Create two columns of arrays\n",
    "columns = [\"name\", \"language\", \"type\"]\n",
    "shows_map = shows.select(\n",
    "    *[F.lit(column) for column in columns],\n",
    "    F.array(*columns).alias(\"values\")\n",
    ")\n",
    "shows_map = shows_map.select(F.array(*columns).alias(\"keys\"), \"values\")\n",
    "print(\"Two columns of arays\")\n",
    "shows_map.show(1, False)\n",
    "\n",
    "# 2. Map them together using one array as the key, and other as value\n",
    "shows_map = shows_map.select(\n",
    "    F.map_from_arrays(\"keys\", \"values\").alias(\"mapped\")\n",
    ")\n",
    "shows_map.printSchema()\n",
    "print(\"1 column of map\")\n",
    "shows_map.show(1, False)\n",
    "\n",
    "# 3. 3 ways to select a key in a map column\n",
    "print(\"3 ways to select a key in a map\")\n",
    "shows_map.select(\n",
    "    F.col(\"mapped.name\"), # dot_notation with col\n",
    "    F.col(\"mapped\")[\"name\"], # Python dictionary style\n",
    "    shows_map.mapped[\"name\"] # dot_notation to get the column + bracket\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `struct`\n",
    "\n",
    "- Similar to JSON object.  Key is a string and record can be of a different type.\n",
    "- Unlike array & map, __the number of fields and their names are known ahead of time__\n",
    "\n",
    "\n",
    "![](notes/img/struct.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"schedule\" column contain array of strings and a string\n",
    "shows.select(\"schedule\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](notes/img/embedded.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A more complex struct\n",
    "shows.select(\"_embedded\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above `struct` visualized:\n",
    "![](notes/img/embedded.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- episodes: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- number: long (nullable = true)\n",
      " |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |-- season: long (nullable = true)\n",
      " |    |    |-- summary: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop useless _embedded column and promote the fields within\n",
    "shows_clean = shows.withColumn(\"episodes\", F.col(\"_embedded.episodes\")).drop(\n",
    "    \"_embedded\"\n",
    ")\n",
    "shows_clean.select(\"episodes\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `explode` to split arrays into rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+-------------------------+\n",
      "|name                     |\n",
      "+-------------------------+\n",
      "|Minimum Viable Product   |\n",
      "|The Cap Table            |\n",
      "|Articles of Incorporation|\n",
      "+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"episodes.name\" == array of strings\n",
    "episodes_name = shows_clean.select(F.col(\"episodes.name\"))\n",
    "episodes_name.printSchema()\n",
    "\n",
    "# Just showing episodes_name is messy, so explode the array to show the names\n",
    "episodes_name.select(F.explode(\"name\").alias(\"name\")).show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to define and use a schema with a PySpark data frame\n",
    "\n",
    "- Can build either 1) programmatically, or 2) DDL-style schema\n",
    "- Type objects used to build schema located in `pyspark.sql.types`, usually imported as `T`.\n",
    "\n",
    "Two object types in `pyspark.sql.types`\n",
    "1. types object - represent column of a certain type (e.g. `LongType()`, `DecimalType(precision, scale)`, `ArrayType(StringType())`, etc.\n",
    "2. field object - represent arbitrary number of named fields (e.g. StructField())\n",
    "  - 2 mandatory params, `name` (str) and `dataType` (type)\n",
    "  \n",
    "Putting it altogether:\n",
    "```\n",
    "T.StructField(\"summary\", T.StringType())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For reference\n",
    "shows.select(\"_embedded\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the entire schema from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full schema from scratch\n",
    "\n",
    "# episode links\n",
    "episode_links_schema = T.StructType(\n",
    "    [T.StructField(\"self\", T.StructType([T.StructField(\"href\", T.StringType())]))]\n",
    ")\n",
    "\n",
    "# episode image\n",
    "episode_image_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"medium\", T.StringType()),\n",
    "        T.StructField(\"original\", T.StringType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# episode metadata\n",
    "episode_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"_links\", episode_links_schema),\n",
    "        T.StructField(\"airdate\", T.DateType()),\n",
    "        T.StructField(\"airstamp\", T.TimestampType()),\n",
    "        T.StructField(\"airtime\", T.StringType()),\n",
    "        T.StructField(\"id\", T.StringType()),\n",
    "        T.StructField(\"image\", episode_image_schema),\n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "        T.StructField(\"number\", T.LongType()),\n",
    "        T.StructField(\"runtime\", T.LongType()),\n",
    "        T.StructField(\"season\", T.LongType()),\n",
    "        T.StructField(\"summary\", T.StringType()),\n",
    "        T.StructField(\"url\", T.StringType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# set top level array\n",
    "embedded_schema = T.StructType([T.StructField(\"episodes\", T.ArrayType(episode_schema))])\n",
    "\n",
    "# network\n",
    "network_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\n",
    "            \"country\",\n",
    "            T.StructType(\n",
    "                [\n",
    "                    T.StructField(\"code\", T.StringType()),\n",
    "                    T.StructField(\"name\", T.StringType()),\n",
    "                    T.StructField(\"timezone\", T.StringType()),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        T.StructField(\"id\", T.LongType()),\n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# shows (with embedded_schema and network_schema)\n",
    "shows_schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"_embedded\", embedded_schema),\n",
    "        T.StructField(\"language\", T.StringType()),\n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "        T.StructField(\"network\", network_schema),\n",
    "        T.StructField(\"officialSite\", T.StringType()),\n",
    "        T.StructField(\"premiered\", T.StringType()),\n",
    "        T.StructField(\n",
    "            \"rating\", T.StructType([T.StructField(\"average\", T.DoubleType())])\n",
    "        ),\n",
    "        T.StructField(\"runtime\", T.LongType()),\n",
    "        T.StructField(\n",
    "            \"schedule\",\n",
    "            T.StructType(\n",
    "                [\n",
    "                    T.StructField(\"days\", T.ArrayType(T.StringType())),\n",
    "                    T.StructField(\"time\", T.StringType()),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        T.StructField(\"status\", T.StringType()),\n",
    "        T.StructField(\"summary\", T.StringType()),\n",
    "        T.StructField(\"type\", T.StringType()),\n",
    "        T.StructField(\"updated\", T.LongType()),\n",
    "        T.StructField(\"url\", T.StringType()),\n",
    "        T.StructField(\"webChannel\", T.StringType()),\n",
    "        T.StructField(\"weight\", T.LongType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON with a strict schema\n",
    "\n",
    "Read the JSON file using the schema that we built up:\n",
    "- `mode=\"FAILFAST\"` is a param to throw an error if it reads a malformed record versus the schema provided.\n",
    "- If reading non-standard date/timestamp format, you'll need to pass the right format to `dateFormat` or `timestampFormat`.\n",
    "\n",
    "> Default for `mode` parameter is `PERMISSIVE`, which sets malformed records to `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|col       |\n",
      "+----------+\n",
      "|2014-04-06|\n",
      "|2014-04-13|\n",
      "|2014-04-20|\n",
      "|2014-04-27|\n",
      "|2014-05-04|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+\n",
      "|col                |\n",
      "+-------------------+\n",
      "|2014-04-06 22:00:00|\n",
      "|2014-04-13 22:00:00|\n",
      "|2014-04-20 22:00:00|\n",
      "|2014-04-27 22:00:00|\n",
      "|2014-05-04 22:00:00|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_with_schema = spark.read.json(\"./data/Ch06/shows-silicon-valley.json\",\n",
    "                                   schema=shows_schema,\n",
    "                                   mode=\"FAILFAST\")\n",
    "\n",
    "# Check format for modified columns:\n",
    "for column in [\"airdate\", \"airstamp\"]:\n",
    "    shows_with_schema.select(f\"_embedded.episodes.{column}\") \\\n",
    "                     .select(F.explode(column)) \\\n",
    "                     .show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `FAILFAST` error due to conflicting schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "shows_schema2 = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"_embedded\", embedded_schema),\n",
    "        T.StructField(\"language\", T.StringType()),\n",
    "        T.StructField(\"name\", T.StringType()),\n",
    "        T.StructField(\"network\", network_schema),\n",
    "        T.StructField(\"officialSite\", T.StringType()),\n",
    "        T.StructField(\"premiered\", T.StringType()),\n",
    "        T.StructField(\n",
    "            \"rating\", T.StructType([T.StructField(\"average\", T.DoubleType())])\n",
    "        ),\n",
    "        T.StructField(\"runtime\", T.LongType()),\n",
    "        T.StructField(\n",
    "            \"schedule\",\n",
    "            T.StructType(\n",
    "                [\n",
    "                    T.StructField(\"days\", T.ArrayType(T.StringType())),\n",
    "                    T.StructField(\"time\", T.StringType()),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        T.StructField(\"status\", T.StringType()),\n",
    "        T.StructField(\"summary\", T.StringType()),\n",
    "        T.StructField(\"type\", T.LongType()),         # switch to LongType\n",
    "        T.StructField(\"updated\", T.LongType()),      # switch to LongType\n",
    "        T.StructField(\"url\", T.LongType()),          # switch to LongType\n",
    "        T.StructField(\"webChannel\", T.StringType()),\n",
    "        T.StructField(\"weight\", T.LongType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "shows_with_schema_wrong = spark.read.json(\n",
    "    \"data/Ch06/shows-silicon-valley.json\", schema=shows_schema2, mode=\"FAILFAST\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    shows_with_schema_wrong.show()\n",
    "except Py4JJavaError:\n",
    "    pass\n",
    "\n",
    "# Huge Spark ERROR stacktrace, relevant bit:\n",
    "#\n",
    "# Caused by: java.lang.RuntimeException: Failed to parse a value for data type\n",
    "#   bigint (current token: VALUE_STRING)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining your schema in JSON\n",
    "\n",
    "StructType comes with two methods for exporting its content into a JSON-esque format.\n",
    "1. `json()` outputs a string containing the json formatted schema\n",
    "2. `jsonValue()` returns the schema as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': [{'metadata': {},\n",
      "             'name': 'schedule',\n",
      "             'nullable': True,\n",
      "             'type': {'fields': [{'metadata': {},\n",
      "                                  'name': 'days',\n",
      "                                  'nullable': True,\n",
      "                                  'type': {'containsNull': True,\n",
      "                                           'elementType': 'string',\n",
      "                                           'type': 'array'}},\n",
      "                                 {'metadata': {},\n",
      "                                  'name': 'time',\n",
      "                                  'nullable': True,\n",
      "                                  'type': 'string'}],\n",
      "                      'type': 'struct'}}],\n",
      " 'type': 'struct'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(shows_with_schema.select('schedule').schema.jsonValue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `jsonValue` on complex schema to see its JSON representation. This is helpful when trying to remember a complex schema:\n",
    "\n",
    "### Array types\n",
    "  1. `containsNull`,\n",
    "  2. `elementType`,\n",
    "  3. `type` (always array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {},\n",
      " 'name': 'array_example',\n",
      " 'nullable': True,\n",
      " 'type': {'containsNull': True, 'elementType': 'string', 'type': 'array'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(T.StructField(\"array_example\", T.ArrayType(T.StringType())).jsonValue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map types\n",
    "\n",
    "1. `keyType`\n",
    "2. `type` (always map)\n",
    "3. `valueContainsNull`\n",
    "2. `valueType`\n",
    "3. `keyType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {},\n",
      " 'name': 'map_example',\n",
      " 'nullable': True,\n",
      " 'type': {'keyType': 'string',\n",
      "          'type': 'map',\n",
      "          'valueContainsNull': True,\n",
      "          'valueType': 'long'}}\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "pprint(\n",
    "    T.StructField(\"map_example\", T.MapType(T.StringType(), T.LongType())).jsonValue()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': [{'metadata': {},\n",
      "             'name': 'map_example',\n",
      "             'nullable': True,\n",
      "             'type': {'keyType': 'string',\n",
      "                      'type': 'map',\n",
      "                      'valueContainsNull': True,\n",
      "                      'valueType': 'long'}},\n",
      "            {'metadata': {},\n",
      "             'name': 'array_example',\n",
      "             'nullable': True,\n",
      "             'type': {'containsNull': True,\n",
      "                      'elementType': 'string',\n",
      "                      'type': 'array'}}],\n",
      " 'type': 'struct'}\n"
     ]
    }
   ],
   "source": [
    "# With both\n",
    "pprint(\n",
    "    T.StructType(\n",
    "        [\n",
    "            T.StructField(\"map_example\", T.MapType(T.StringType(), T.LongType())),\n",
    "            T.StructField(\"array_example\", T.ArrayType(T.StringType())),\n",
    "        ]\n",
    "    ).jsonValue()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally, we can close the loop by making sure that our JSON-schema is consistent with the one currently being used. For this, we’ll export the schema of shows_with_schema in a JSON string, load it as a JSON object and then use StructType.fromJson() method to re-create the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "other_shows_schema = T.StructType.fromJson(json.loads(shows_with_schema.schema.json()))\n",
    "\n",
    "print(other_shows_schema == shows_with_schema.schema)  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing duplicate data with complex data types\n",
    "\n",
    "### Hierarchichal vs 2-D row-column models\n",
    "\n",
    "If we were to make the `shows` data frame in a traditional relational database, we could have a `shows` table linked to an `episodes` table using a star schema.\n",
    "\n",
    " `shows` table\n",
    "\n",
    "| show_id | name           |\n",
    "|---------|----------------|\n",
    "| 143     | silicon valley |\n",
    "\n",
    "`episodes` table, joined to `shows` by `show_id`\n",
    "\n",
    "| show_id | episode_id     | name           |\n",
    "|---------|----------------|----------------|\n",
    "| 143     | 1 | Minimal Viable Product |\n",
    "| 143     | 2 | The Cap Table |\n",
    "| 143     | 3 | Articles of Incorporation |\n",
    "\n",
    "`episodes` could be extended with more columns, but starts to have duplicate entries\n",
    "\n",
    "| show_id | episode_id     | name           | genre           | day           |\n",
    "|---------|----------------|----------------|----------------|----------------|\n",
    "| 143     | 1 | Minimal Viable Product | Comedy | Sunday |\n",
    "| 143     | 2 | The Cap Table | Comedy | Sunday |\n",
    "| 143     | 3 | Articles of Incorporation | Comedy | Sunday |\n",
    "\n",
    "\n",
    "In contrast, a hierarchichal data frame contains complex columns with arrays and struct columns:\n",
    "- each record represents a show;\n",
    "- a show has multiple episodes (array of structs column);\n",
    "- each episode has many fields (struct column within the array);\n",
    "- each show can have multiple genres (array of string column)\n",
    "- each show has a schedule (struct column);\n",
    "- each schedule belonging to a show can have multiple days (array), but a single time (string).\n",
    "\n",
    "\n",
    "#### `shows` data frame using a hierarchical model\n",
    "\n",
    "![](./notes/img/hier_df.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use `explode` and `collect` operations to go from hierarchical to tabular and back\n",
    "\n",
    "> We will now revisit the exploding operation by generalizing it to the map, looking at the behavior when your data frame has multiple columns, and see the different options PySpark provided with exploding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- episodes: struct (nullable = true)\n",
      " |    |-- _links: struct (nullable = true)\n",
      " |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |-- href: string (nullable = true)\n",
      " |    |-- airdate: string (nullable = true)\n",
      " |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |-- airtime: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- image: struct (nullable = true)\n",
      " |    |    |-- medium: string (nullable = true)\n",
      " |    |    |-- original: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- number: long (nullable = true)\n",
      " |    |-- runtime: long (nullable = true)\n",
      " |    |-- season: long (nullable = true)\n",
      " |    |-- summary: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      "\n",
      "+---+--------------------+\n",
      "| id|            episodes|\n",
      "+---+--------------------+\n",
      "|143|[[[http://api.tvm...|\n",
      "|143|[[[http://api.tvm...|\n",
      "|143|[[[http://api.tvm...|\n",
      "|143|[[[http://api.tvm...|\n",
      "|143|[[[http://api.tvm...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploding _embeedded.episodes\n",
    "episodes = shows.select(\"id\", F.explode(\"_embedded.episodes\").alias(\"episodes\"))\n",
    "episodes.printSchema()\n",
    "episodes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding a `map`\n",
    "\n",
    "- keys and values exploded in two different fields\n",
    "- `posexplode`: explodes the column and also returns an additional column before the data that contains the array positions (LongType).\n",
    "- `explode` / `posexplode` skips null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-------------------------+\n",
      "|position|id   |name                     |\n",
      "+--------+-----+-------------------------+\n",
      "|0       |10897|Minimum Viable Product   |\n",
      "|1       |10898|The Cap Table            |\n",
      "|2       |10899|Articles of Incorporation|\n",
      "|3       |10900|Fiduciary Duties         |\n",
      "|4       |10901|Signaling Risk           |\n",
      "+--------+-----+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "episode_name_id = shows.select(\n",
    "    F.map_from_arrays(\n",
    "        F.col(\"_embedded.episodes.id\"), F.col(\"_embedded.episodes.name\")\n",
    "    ).alias(\"name_id\")\n",
    ")\n",
    "\n",
    "episode_name_id = episode_name_id.select(\n",
    "    F.posexplode(\"name_id\").alias(\"position\", \"id\", \"name\")\n",
    ")\n",
    "\n",
    "episode_name_id.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `collect`-ing records into a complex column\n",
    "\n",
    "#### `collect_list()` and `collect_set()`\n",
    "\n",
    "- takes column as arg, returns an array column\n",
    "- collect_list = 1 array per column record\n",
    "- collect_set = 1 array per distinct column record (like Python set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- episodes: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = false)\n",
      " |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- number: long (nullable = true)\n",
      " |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |-- season: long (nullable = true)\n",
      " |    |    |-- summary: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collected = episodes.groupby(\"id\").agg(F.collect_list(\"episodes\").alias(\"episodes\"))\n",
    "print(collected.count())\n",
    "collected.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building your own hierarchies with `struct()`\n",
    "\n",
    "`struct()` function takess columns as params, and returns struct column containing the columns passed as params as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|info             |\n",
      "+-----------------+\n",
      "|[Ended, 96, true]|\n",
      "+-----------------+\n",
      "\n",
      "root\n",
      " |-- info: struct (nullable = false)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- weight: long (nullable = true)\n",
      " |    |-- has_watched: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a struct column\n",
    "\n",
    "struct_ex = shows.select(\n",
    "    F.struct(\n",
    "        F.col(\"status\"), F.col(\"weight\"), F.lit(True).alias(\"has_watched\")\n",
    "    ).alias(\"info\")\n",
    ")\n",
    "\n",
    "struct_ex.show(1, False)\n",
    "\n",
    "struct_ex.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: timestamp (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark]",
   "language": "python",
   "name": "conda-env-pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
