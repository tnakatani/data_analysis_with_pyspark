{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Joining-Data\" data-toc-modified-id=\"Joining-Data-1\">Joining Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Understanding-the-join-recipe\" data-toc-modified-id=\"Understanding-the-join-recipe-1.1\">Understanding the <code>join</code> recipe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Important-points\" data-toc-modified-id=\"Important-points-1.1.1\">Important points</a></span></li><li><span><a href=\"#Pyspark-helpers-in-join-logic\" data-toc-modified-id=\"Pyspark-helpers-in-join-logic-1.1.2\">Pyspark helpers in join logic</a></span></li><li><span><a href=\"#Setting-up-join-logic-with-how\" data-toc-modified-id=\"Setting-up-join-logic-with-how-1.1.3\">Setting up join logic with <code>how</code></a></span></li></ul></li><li><span><a href=\"#Warning:-What-happens-when-joining-columns-in-a-distributed-environment\" data-toc-modified-id=\"Warning:-What-happens-when-joining-columns-in-a-distributed-environment-1.2\">Warning: What happens when joining columns in a distributed environment</a></span></li><li><span><a href=\"#Warning:-Joining-tables-with-identically-named-columns-leads-to-errors-downstream\" data-toc-modified-id=\"Warning:-Joining-tables-with-identically-named-columns-leads-to-errors-downstream-1.3\">Warning: Joining tables with identically named columns leads to errors downstream</a></span></li><li><span><a href=\"#Solutions-for-preventing-ambiguous-column-references\" data-toc-modified-id=\"Solutions-for-preventing-ambiguous-column-references-1.4\">Solutions for preventing ambiguous column references</a></span></li></ul></li><li><span><a href=\"#Advanced-groupby-with-GroupedData\" data-toc-modified-id=\"Advanced-groupby-with-GroupedData-2\">Advanced <code>groupby</code> with <code>GroupedData</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#groupby-on-multiple-columns\" data-toc-modified-id=\"groupby-on-multiple-columns-2.1\"><code>groupby</code> on multiple columns</a></span></li><li><span><a href=\"#agg()-vs-sum()\" data-toc-modified-id=\"agg()-vs-sum()-2.2\"><code>agg()</code> vs <code>sum()</code></a></span></li><li><span><a href=\"#Using-agg-with-custom-column-definitions\" data-toc-modified-id=\"Using-agg-with-custom-column-definitions-2.3\">Using agg with custom column definitions</a></span></li></ul></li><li><span><a href=\"#Dropping-unwanted-records---dropna-+-fillna\" data-toc-modified-id=\"Dropping-unwanted-records---dropna-+-fillna-3\">Dropping unwanted records - <code>dropna</code> + <code>fillna</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#dropna\" data-toc-modified-id=\"dropna-3.1\"><code>dropna</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#params\" data-toc-modified-id=\"params-3.1.1\">params</a></span></li></ul></li><li><span><a href=\"#fillna\" data-toc-modified-id=\"fillna-3.2\"><code>fillna</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#params\" data-toc-modified-id=\"params-3.2.1\">params</a></span></li></ul></li></ul></li><li><span><a href=\"#Pulling-it-all-together\" data-toc-modified-id=\"Pulling-it-all-together-4\">Pulling it all together</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: string (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: string (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- LogIdentifierID: string (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- PrimaryFG: integer (nullable = true)\n",
      "\n",
      "+---------------+------------+---------+\n",
      "|LogIdentifierID|LogServiceID|PrimaryFG|\n",
      "+---------------+------------+---------+\n",
      "|           13ST|        3157|        1|\n",
      "|         2000SM|        3466|        1|\n",
      "|           70SM|        3883|        1|\n",
      "|           80SM|        3590|        1|\n",
      "|           90SM|        3470|        1|\n",
      "+---------------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Unique primary channels:  758\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Read the data\n",
    "DIRECTORY = \"./data/Ch04\"\n",
    "logs = spark.read.csv(\n",
    "    \"./output/ch04/logs.csv\", # read in data transformed in Ch04\n",
    "    sep=\",\",  # default is \",\"\n",
    "    quote='\"',  # default is double quote.\n",
    "    header=True,  # set first row as column names\n",
    "    inferSchema=True,  # infer schema from column names default False\n",
    ")\n",
    "logs.printSchema()\n",
    "\n",
    "\n",
    "# Read link table and filter to only primary channels (ie. PrimaryFG == 1)\n",
    "log_identifier = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"ReferenceTables\", \"LogIdentifier.csv\"),\n",
    "    sep=\"|\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ")\n",
    "log_identifier = log_identifier.where(F.col(\"PrimaryFG\") == 1)\n",
    "\n",
    "\n",
    "# Show results\n",
    "log_identifier.printSchema()\n",
    "log_identifier.show(5)\n",
    "print(\"Unique primary channels: \", log_identifier.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the `join` recipe\n",
    "\n",
    "```py\n",
    "[LEFT].join(\n",
    "    [RIGHT],\n",
    "    on=[PREDICTES],\n",
    "    how=[METHOD]\n",
    ")\n",
    "```\n",
    "\n",
    "#### Important points\n",
    "\n",
    "1. If one record in the left table resolves the predicate with more than one record in the right table (or vice versa), __this record will be duplicated in the joined table__.\n",
    "2. If one record in the left or in the right table does not resolve the predicate with any record in the other table, __it will not be present in the resulting table, unless the join method specifies a protocol for failed predicates__.\n",
    "\n",
    "#### Pyspark helpers in join logic\n",
    "\n",
    "- You can put multiple `and` predicates into a list, like:\n",
    "    ```py\n",
    "    [\n",
    "        left[\"col1\"] == right[\"colA\"], \n",
    "        left[\"col2\"] > right[\"colB\"],  # value on left table is greater than the right\n",
    "        left[\"col3\"] != right[\"colC\"]\n",
    "    ]\n",
    "    ```\n",
    "- You can test equality just by specifying the column name, or list of column names\n",
    "\n",
    "#### Setting up join logic with `how`\n",
    "\n",
    "1. `cross` - returns a record for every record pair. not common.\n",
    "2. `inner` = returns record if predicate is true, otherwise drops it. most common, pyspark `join` default. \n",
    "3. `left` & `right` - similar to `inner`, except on what to do with false predicates:\n",
    "    - `left` join adds unmatched records from the left table in the joined table, and fills in columns from right able with `None`\n",
    "    - `right` join adds unmatched records nad fills in column vice versa.\n",
    "4. `outer` - adds unmatched records from the left and right able, padding with `None`.\n",
    "5. `left_semi` - same as inner join but only keeps columns in left table. \n",
    "6. `left_anti` - returns only records that don't match the predicate with any record in the right table.  opposite of `left` join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join `logs` with `log_identifier` using the 'LogServiceID' column\n",
    "joined = logs.join(log_identifier, on=\"LogServiceID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogDate: string (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: string (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      " |-- LogIdentifierID: string (nullable = true)\n",
      " |-- PrimaryFG: integer (nullable = true)\n",
      " |-- CategoryCD: string (nullable = true)\n",
      " |-- Category_Description: string (nullable = true)\n",
      " |-- ProgramClassCD: string (nullable = true)\n",
      " |-- ProgramClass_Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Additionally join CategoryID and ProgramClassID table\n",
    "# Use left joins since keys may not be available in the link table.\n",
    "\n",
    "# CategoryID\n",
    "cd_category = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"ReferenceTables\", \"CD_Category.csv\"),\n",
    "    sep=\"|\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ").select(\n",
    "    \"CategoryID\",\n",
    "    \"CategoryCD\",\n",
    "    F.col(\"EnglishDescription\").alias(\"Category_Description\"),\n",
    ")\n",
    "\n",
    "# ProgramClass\n",
    "cd_program_class = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"ReferenceTables\", \"CD_ProgramClass.csv\"),\n",
    "    sep=\"|\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ").select(\n",
    "    \"ProgramClassID\",\n",
    "    \"ProgramClassCD\",\n",
    "    F.col(\"EnglishDescription\").alias(\"ProgramClass_Description\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Join all to joined table\n",
    "full_log = joined.join(cd_category, \"CategoryID\", how=\"left\",).join(\n",
    "    cd_program_class, \"ProgramClassID\", how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "# Check if additional columns were joined to original log data frame\n",
    "full_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: What happens when joining columns in a distributed environment\n",
    "\n",
    ">  To be able to process a comparison between records, the data needs to be on the same machine. If not, PySpark will move the data in an operation called a _shuffle_, which is slow and expensive.  More on join strategies in later chapters.\n",
    "\n",
    "### Warning: Joining tables with identically named columns leads to errors downstream\n",
    "\n",
    "PySpark happily joins the two data frames together but fails when we try to work with the ambiguous column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: string (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: string (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      " |-- LogIdentifierID: string (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- PrimaryFG: integer (nullable = true)\n",
      "\n",
      "Joined table now has two \"LogServiceID\" columns:  ['LogServiceID', 'LogServiceID'] \n",
      "\n",
      "Selecting \"LogServiceID\" will now throw an error\n",
      "AnalysisException:  Reference 'LogServiceID' is ambiguous, could be: LogServiceID, LogServiceID.;\n"
     ]
    }
   ],
   "source": [
    "# Joining two tables with the same LogServiceID column\n",
    "logs_and_channels_verbose = logs.join(\n",
    "    log_identifier, logs[\"LogServiceID\"] == log_identifier[\"LogServiceID\"]\n",
    ")\n",
    "logs_and_channels_verbose.printSchema()\n",
    "\n",
    "\n",
    "print(\n",
    "    'Joined table now has two \"LogServiceID\" columns: ',\n",
    "    [col for col in logs_and_channels_verbose.columns if col == \"LogServiceID\"],\n",
    "    \"\\n\",\n",
    ")\n",
    "print('Selecting \"LogServiceID\" will now throw an error')\n",
    "\n",
    "\n",
    "# Selecting \"LogServiceID\" will throw an error\n",
    "try:\n",
    "    logs_and_channels_verbose.select(\"LogServiceID\")\n",
    "except AnalysisException as err:\n",
    "    print(\"AnalysisException: \", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions for preventing ambiguous column references\n",
    "\n",
    "1. Use simplified syntax (ie. passing string of column you want). Auto-removes second instance of predicate column.  Can only use on equi-joins.\n",
    "    ```\n",
    "    logs_and_channels = logs.join(log_identifier, \"LogServiceID\")\n",
    "    ```\n",
    "2. Refer to the pre-existing table name.\n",
    "    ```\n",
    "    logs_and_channels_verbose.select(log_identifier[\"LogServiceID\"])\n",
    "    ```\n",
    "3. Use the `Column` object directly\n",
    "    ```\n",
    "    logs_and_channels_verbose = logs.alias(\"left\").join(\n",
    "    log_identifier.alias(\"right\"),\n",
    "    logs[\"LogServiceID\"] == log_identifier[\"LogServiceID\"],\n",
    "    )\n",
    "\n",
    "    logs_and_channels_verbose.drop(F.col(\"right.LogServiceID\")).select(\n",
    "        \"LogServiceID\"\n",
    "    )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced `groupby` with `GroupedData`\n",
    "\n",
    "Goal: __What channels have the most and least proportion of commercials?__\n",
    "\n",
    "Task:\n",
    "1. Get number of seconds when the program is a commerical\n",
    "2. Get total number of seconds.\n",
    "\n",
    "### `groupby` on multiple columns\n",
    "\n",
    "- Grouped by results are `GroupedData` objects, not `data frame`.  Can't call `show()` on it.\n",
    "- You can \"show\" by running summary functions on it, like `F.sum`.\n",
    "- `GroupedData` object holds all non-key columns in a group cell (see fig 5.7)\n",
    "\n",
    "![grouped](./notes/img/grouped.png)\n",
    "\n",
    "\n",
    "### `agg()` vs `sum()`\n",
    "\n",
    "- `agg` can take an arbitrary number of aggregate functions\n",
    "- You can alias resulting columns, unlike `sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------------+--------------+\n",
      "|ProgramClassCD|ProgramClass_Description              |duration_total|\n",
      "+--------------+--------------------------------------+--------------+\n",
      "|PGR           |PROGRAM                               |20992510      |\n",
      "|COM           |COMMERCIAL MESSAGE                    |3519163       |\n",
      "|PFS           |PROGRAM FIRST SEGMENT                 |1344762       |\n",
      "|SEG           |SEGMENT OF A PROGRAM                  |1205998       |\n",
      "|PRC           |PROMOTION OF UPCOMING CANADIAN PROGRAM|880600        |\n",
      "|PGI           |PROGRAM INFOMERCIAL                   |679182        |\n",
      "|PRO           |PROMOTION OF NON-CANADIAN PROGRAM     |335701        |\n",
      "|OFF           |SCHEDULED OFF AIR TIME PERIOD         |142279        |\n",
      "|ID            |NETWORK IDENTIFICATION MESSAGE        |74926         |\n",
      "|NRN           |No recognized nationality             |59686         |\n",
      "|MAG           |MAGAZINE PROGRAM                      |57622         |\n",
      "|PSA           |PUBLIC SERVICE ANNOUNCEMENT           |51214         |\n",
      "|SO            |MAY IDENTIFY THE SIGN ON\\OFF OF A DAY |32509         |\n",
      "|OFT           |OFF AIR DUE TO TECHNICAL DIFFICULTY   |18263         |\n",
      "|LOC           |LOCAL ADVERTISING                     |13294         |\n",
      "|MVC           |MUSIC VIDEO CLIP                      |7907          |\n",
      "|REG           |REGIONAL                              |6749          |\n",
      "|MER           |MERCHANDISING                         |1680          |\n",
      "|SPO           |SPONSORSHIP MESSAGE                   |1544          |\n",
      "|SOL           |SOLICITATION MESSAGE                  |596           |\n",
      "|MOS           |Mosaic                                |null          |\n",
      "|COR           |CORNERSTONE                           |null          |\n",
      "+--------------+--------------------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by ProgramClassCD and ProgramClass_Description, sum total duration for each\n",
    "\n",
    "full_log.groupby(\"ProgramClassCD\", \"ProgramClass_Description\").agg(\n",
    "    F.sum(\"duration_seconds\").alias(\"duration_total\")\n",
    ").orderBy(\"duration_total\", ascending=False).show(100, False)\n",
    "\n",
    "\n",
    "# Another way by passing dictionary to agg\n",
    "# full_log.groupby(\"ProgramClassCD\", \"ProgramClass_Description\").agg(\n",
    "#     {\"duration_seconds\": \"sum\"}\n",
    "# ).withColumnRenamed(\"sum(duration_seconds)\", \"duration_total\").orderBy(\n",
    "#     \"duration_total\", ascending=False\n",
    "# ).show(\n",
    "#     100, False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using agg with custom column definitions\n",
    "\n",
    "`when` logic:\n",
    "\n",
    "```py\n",
    "(\n",
    "F.when([BOOLEAN TEST], [RESULT IF TRUE])\n",
    " .when([ANOTHER BOOLEAN TEST], [RESULT IF TRUE])\n",
    " .otherwise([DEFAULT RESULT, WILL DEFAULT TO null IF OMITTED])\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------+------------------+\n",
      "|LogIdentifierID|duration_commercial|duration_total|commercial_ratio  |\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "|CIMT           |775                |775           |1.0               |\n",
      "|TELENO         |17790              |17790         |1.0               |\n",
      "|MSET           |2700               |2700          |1.0               |\n",
      "|HPITV          |13                 |13            |1.0               |\n",
      "|TLNSP          |15480              |15480         |1.0               |\n",
      "|TANG           |8125               |8125          |1.0               |\n",
      "|MMAX           |23333              |23582         |0.9894410991434145|\n",
      "|MPLU           |20587              |20912         |0.9844586840091814|\n",
      "|INVST          |20094              |20470         |0.9816316560820714|\n",
      "|ZT�L�          |21542              |21965         |0.9807420896881403|\n",
      "|RAPT           |17916              |18279         |0.9801411455768915|\n",
      "|CANALD         |21437              |21875         |0.9799771428571429|\n",
      "|ONEBMS         |18084              |18522         |0.9763524457402009|\n",
      "|CANALVIE       |20780              |21309         |0.975174808766249 |\n",
      "|unis           |11630              |11998         |0.9693282213702283|\n",
      "|CIVM           |11370              |11802         |0.9633960345704118|\n",
      "|TV5            |10759              |11220         |0.9589126559714795|\n",
      "|LEAF           |11526              |12034         |0.9577862722286854|\n",
      "|VISION         |12946              |13621         |0.950444167094927 |\n",
      "|CJIL           |3904               |4213          |0.9266555898409684|\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Goal: Compute only the commercial time for each program\n",
    "\n",
    "\n",
    "# Create custom column logic - get duration_seconds if ProgramClassCD matches an item in\n",
    "# the list\n",
    "is_commercial = F.when(\n",
    "    F.trim(F.col(\"ProgramClassCD\")).isin(\n",
    "        [\"COM\", \"PRC\", \"PGI\", \"PRO\", \"LOC\", \"SPO\", \"MER\", \"SOL\"]\n",
    "    ),\n",
    "    F.col(\"duration_seconds\"),\n",
    ").otherwise(0)\n",
    "\n",
    "\n",
    "# Use custom column logic to build a duration_commercial column,\n",
    "# along with duration_total\n",
    "commercial_time = (\n",
    "    full_log.groupby(\"LogIdentifierID\")\n",
    "    .agg(\n",
    "        F.sum(is_commercial).alias(\"duration_commercial\"),\n",
    "        F.sum(\"duration_seconds\").alias(\"duration_total\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"commercial_ratio\", F.col(\"duration_commercial\") / F.col(\"duration_total\")\n",
    "    )\n",
    ")\n",
    "\n",
    "commercial_time.orderBy(\"commercial_ratio\", ascending=False).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unwanted records - `dropna` + `fillna`\n",
    "\n",
    "### `dropna`\n",
    "\n",
    "#### params\n",
    "1. `how`, which can take the value any or all. If any is selected, PySpark will drop records where at least one of the fields are null. In the case of all, only the records where all fields are null will be removed. By default, PySpark will take the any mode.\n",
    "2. `thresh` takes an integer value. If set (its default is None), PySpark will ignore the how parameter and only drop the records with less than thresh non-null values.\n",
    "3. `subset` will take an optional list of columns that drop will use to make its decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------+------------------+\n",
      "|LogIdentifierID|duration_commercial|duration_total|  commercial_ratio|\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "|          HPITV|                 13|            13|               1.0|\n",
      "|           CIMT|                775|           775|               1.0|\n",
      "|           MSET|               2700|          2700|               1.0|\n",
      "|          TLNSP|              15480|         15480|               1.0|\n",
      "|         TELENO|              17790|         17790|               1.0|\n",
      "|           TANG|               8125|          8125|               1.0|\n",
      "|           MMAX|              23333|         23582|0.9894410991434145|\n",
      "|           MPLU|              20587|         20912|0.9844586840091814|\n",
      "|          INVST|              20094|         20470|0.9816316560820714|\n",
      "|          ZT�L�|              21542|         21965|0.9807420896881403|\n",
      "|           RAPT|              17916|         18279|0.9801411455768915|\n",
      "|         CANALD|              21437|         21875|0.9799771428571429|\n",
      "|         ONEBMS|              18084|         18522|0.9763524457402009|\n",
      "|       CANALVIE|              20780|         21309| 0.975174808766249|\n",
      "|           unis|              11630|         11998|0.9693282213702283|\n",
      "|           CIVM|              11370|         11802|0.9633960345704118|\n",
      "|            TV5|              10759|         11220|0.9589126559714795|\n",
      "|           LEAF|              11526|         12034|0.9577862722286854|\n",
      "|         VISION|              12946|         13621| 0.950444167094927|\n",
      "|           CJIL|               3904|          4213|0.9266555898409684|\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Records in commercial_time:  324\n",
      "Records in c_time_no_null:  322\n"
     ]
    }
   ],
   "source": [
    "# Drop records that have a commericla_ratio of null\n",
    "\n",
    "c_time_no_null = commercial_time.dropna(subset=[\"commercial_ratio\"])\n",
    "c_time_no_null.orderBy(\"commercial_ratio\", ascending=False).show()\n",
    "\n",
    "\n",
    "# Check record counts for each\n",
    "print(\"Records in commercial_time: \", commercial_time.count())\n",
    "print(\"Records in c_time_no_null: \", c_time_no_null.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fillna`\n",
    "\n",
    "#### params\n",
    "\n",
    "1. `value`, either a Python int, float, string or bool.\n",
    "2. `subset`, which columns to fill\n",
    "\n",
    "__Tip__: You can fill nulls differently for each column by passing a dictionary:\n",
    "\n",
    "```py\n",
    "answer_no_null = answer.fillna(\n",
    "    {\"duration_commercial\": 0, \"duration_total\": 0, \"commercial_ratio\": 0}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------+------------------+\n",
      "|LogIdentifierID|duration_commercial|duration_total|  commercial_ratio|\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "|           CIMT|                775|           775|               1.0|\n",
      "|           MSET|               2700|          2700|               1.0|\n",
      "|          TLNSP|              15480|         15480|               1.0|\n",
      "|          HPITV|                 13|            13|               1.0|\n",
      "|         TELENO|              17790|         17790|               1.0|\n",
      "|           TANG|               8125|          8125|               1.0|\n",
      "|           MMAX|              23333|         23582|0.9894410991434145|\n",
      "|           MPLU|              20587|         20912|0.9844586840091814|\n",
      "|          INVST|              20094|         20470|0.9816316560820714|\n",
      "|          ZT�L�|              21542|         21965|0.9807420896881403|\n",
      "|           RAPT|              17916|         18279|0.9801411455768915|\n",
      "|         CANALD|              21437|         21875|0.9799771428571429|\n",
      "|         ONEBMS|              18084|         18522|0.9763524457402009|\n",
      "|       CANALVIE|              20780|         21309| 0.975174808766249|\n",
      "|           unis|              11630|         11998|0.9693282213702283|\n",
      "|           CIVM|              11370|         11802|0.9633960345704118|\n",
      "|            TV5|              10759|         11220|0.9589126559714795|\n",
      "|           LEAF|              11526|         12034|0.9577862722286854|\n",
      "|         VISION|              12946|         13621| 0.950444167094927|\n",
      "|           CJIL|               3904|          4213|0.9266555898409684|\n",
      "+---------------+-------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Records in commercial_time:  324\n",
      "Records in c_time_no_null:  324\n"
     ]
    }
   ],
   "source": [
    "# Fill null fields\n",
    "\n",
    "c_time_fill_null = commercial_time.fillna(0)\n",
    "c_time_fill_null.orderBy(\"commercial_ratio\", ascending=False).show()\n",
    "\n",
    "\n",
    "# Check record counts for each\n",
    "print(\"Records in commercial_time: \", commercial_time.count())\n",
    "print(\"Records in c_time_no_null: \", c_time_fill_null.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling it all together\n",
    "\n",
    "[summary code of all the steps taken in this notebook as a spark script](code/Ch04-05/commercials.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark]",
   "language": "python",
   "name": "conda-env-pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
